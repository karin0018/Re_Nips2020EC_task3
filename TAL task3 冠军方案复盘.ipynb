{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy.stats import multinomial\n",
    "import os\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "熵\n",
    "- 公式：$Entropy = - \\sum_{i} P(i)log_2(P(i))$\n",
    "    \n",
    "    $P(i)$ 表示第 i 种状态出现的可能性。\n",
    "- 理解：\n",
    "    是一个衡量概率分布的不确定性的定量指标。\n",
    "    \n",
    "    如果熵比较大(即平均编码长度较长)，意味着这一信息有较多的可能状态，相应的每个状态的可能性比较低；\n",
    "    因此每当来了一个新的信息，我们很难对其作出准确预测，即有着比较大的混乱程度/不确定性/不可预测性。\n",
    "    \n",
    "    并且当一个罕见的信息到达时，比一个常见的信息有着更多的信息量，因为它排除了别的很多的可能性，告诉了我们一个确切的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def entropy(c):\n",
    "    # calculate entropy\n",
    "    result=-1\n",
    "    if(len(c)>0):\n",
    "        result=0\n",
    "    for x in c:\n",
    "        result+=(-x)*math.log(x,2)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training data\n",
    "df = pd.read_csv('../train_data/train_task_3_4.csv')\n",
    "# load side information\n",
    "answer_meta_data = pd.read_csv('../metadata/answer_metadata_task_3_4.csv')\n",
    "question_meta_data = pd.read_csv('../metadata/question_metadata_task_3_4.csv')\n",
    "student_meta_data = pd.read_csv('../metadata/student_metadata_task_3_4.csv')\n",
    "\n",
    "# load the submission csv file\n",
    "submission_file = pd.read_csv('../starter_kit/submission_templates/submission_task_3.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算每道题目答案取值的熵，并做 Z-Score 标准化\n",
    "\n",
    "Z-Score 通过 $(x - \\mu)/ \\delta$ 将两组或多组数据转化为无单位的 Z-Score 分值，使得数据标准统一化，提高了数据可比性，削弱了数据解释性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice_entropy = df.groupby('QuestionId')['AnswerValue'].agg(lambda x:multinomial.entropy(1, x.value_counts(normalize=True)))\n",
    "submission_file['entropy_choice'] = choice_entropy\n",
    "submission_file['z_entropy_choice'] = (submission_file['entropy_choice']-np.mean(submission_file['entropy_choice']))/np.std(submission_file['entropy_choice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对每道题统计学生回答时自信度的平均值，并做 Z-Score 标准化\n",
    "\n",
    "如果题目回答记录中存在 confidence 信息，则计算该题目下的所有已知 confidence 的平均值。\n",
    "\n",
    "若不存在，则用所有已知题目的自信度的均值做填充。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.merge(answer_meta_data, on='AnswerId', how='left')\n",
    "notnull_confidence = new_df[new_df['Confidence'].notnull()]\n",
    "# 按照 QuestionID 分组，并统计 Question_ID 的作答数量\n",
    "que_num = notnull_confidence.groupby('QuestionId')['QuestionId'].agg(lambda x: len(x))\n",
    "num_confid = {}\n",
    "for i in que_num.index:\n",
    "    num_confid[i] = que_num[i]\n",
    "valid_que = []\n",
    "for key, value in num_confid.items():\n",
    "    if value < 20:\n",
    "        pass\n",
    "    else:\n",
    "        valid_que.append(key)\n",
    "notnull_confidence = notnull_confidence[notnull_confidence['QuestionId'].isin(valid_que)]\n",
    "que_avg_confid = {}\n",
    "for idx in notnull_confidence['QuestionId'].unique():\n",
    "    cut = notnull_confidence[notnull_confidence['QuestionId']==idx]\n",
    "    que_avg_confid[idx] = cut['Confidence'].mean()\n",
    "all_que_confid = list(que_avg_confid.values())\n",
    "submission_file['confidence'] = submission_file['QuestionId'].apply(lambda x: que_avg_confid[x] if x in que_avg_confid else np.mean(all_que_confid))\n",
    "submission_file['z_confidence'] = (submission_file['confidence']-np.mean(submission_file['confidence']))/np.std(submission_file['confidence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算所有题目作答情况（正确与否）的熵，并做 Z-Score 标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_entropy = df.groupby('QuestionId')['IsCorrect'].agg(lambda x: multinomial.entropy(1, x.value_counts(normalize=True)))\n",
    "submission_file['right_entropy'] = right_entropy\n",
    "submission_file['z_entropy_right'] = (submission_file['right_entropy']-np.mean(submission_file['right_entropy']))/np.std(submission_file['right_entropy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对每道题目，以小组为单位，计算该题目作答情况的条件熵，并做 Z-Score 标准化\n",
    "\n",
    "条件熵计算公式 ：$H(right\\&wrong|group)$\n",
    "\n",
    "一个题目可以属于多个学生小组，也可以在一个小组中重复出现（即，被组内不同的学生做）\n",
    "\n",
    "one_def: 一个题目（i）的所有作答记录\n",
    "\n",
    "some_res: 记录题目 i 分别在不同组作答情况的熵\n",
    "\n",
    "one_score：题目 i 在不同组作答情况熵的期望，即该题目的条件熵（H）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_condition_entropy(one_df):\n",
    "    some_res = one_df.groupby('GroupId')['IsCorrect'].agg(lambda x: multinomial.entropy(1, x.value_counts(normalize=True)))\n",
    "    one_score = 0\n",
    "    for one_group_idx in some_res.index:\n",
    "        cut_df = one_df[one_df['GroupId']==one_group_idx]\n",
    "        # one_score 是该题目在各个小组内作答情况熵的期望值\n",
    "        one_score += some_res[one_group_idx] * (cut_df.shape[0]/one_df.shape[0])\n",
    "    return one_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_right_group_entropy = {}\n",
    "for one_que_id in new_df.QuestionId.unique():\n",
    "    one_df = new_df[new_df['QuestionId']==one_que_id]\n",
    "    # 计算 conditional entropy\n",
    "    cond_right_group_entropy[one_que_id] = get_one_condition_entropy(one_df)\n",
    "submission_file['cond_entropy_group'] = submission_file['QuestionId'].apply(lambda x: cond_right_group_entropy[x]) # 这里的 apply 可以理解为映射\n",
    "submission_file['z_cond_entropy'] = (submission_file['cond_entropy_group']-submission_file['cond_entropy_group'].mean())/submission_file['cond_entropy_group'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 与上面类似，以题目所在 quiz 为单位，计算作答情况的条件熵，并做 Z-Score 标准化\n",
    "\n",
    "条件熵计算公式 ：$H(right\\&wrong|quiz)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_quiz_condition_entropy(one_df):\n",
    "    some_res = one_df.groupby('QuizId')['IsCorrect'].agg(lambda x: multinomial.entropy(1, x.value_counts(normalize=True)))\n",
    "    one_score = 0\n",
    "    for one_group_idx in some_res.index:\n",
    "        cut_df = one_df[one_df['QuizId']==one_group_idx]\n",
    "        one_score += some_res[one_group_idx] * (cut_df.shape[0]/one_df.shape[0])\n",
    "    return one_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_right_quiz_entropy = {}\n",
    "for one_que_id in new_df.QuestionId.unique():\n",
    "    one_df = new_df[new_df['QuestionId']==one_que_id]\n",
    "    # 计算conditional entropy\n",
    "    cond_right_quiz_entropy[one_que_id] = get_one_quiz_condition_entropy(one_df)\n",
    "submission_file['cond_entropy_quiz'] = submission_file['QuestionId'].apply(lambda x: cond_right_quiz_entropy[x])\n",
    "submission_file['z_cond_quiz_entropy'] = (submission_file['cond_entropy_quiz']-submission_file['cond_entropy_quiz'].mean())/submission_file['cond_entropy_quiz'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 排序\n",
    "\n",
    "z_entropy_choice，z_cond_quiz_entropy，z_entropy_right，z_confidence 加权计算最终分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float0, float_1, float_2 = 0.7, 0.1, 1\n",
    "submission_file['final_score'] = submission_file['z_entropy_choice'] + float0*submission_file['z_cond_entropy'] + \\\n",
    "float_1* submission_file['z_cond_quiz_entropy'] + \\\n",
    "float_2*submission_file['z_entropy_right'] - submission_file['z_confidence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series.rank(method = 'first')根据值在原数据中出现的顺序排名（保留原数据的顺序）\n",
    "ranking = submission_file['final_score'].rank(method='first', ascending=False).astype('int16')\n",
    "submission_file['ranking'] = ranking\n",
    "submission_file[['QuestionId','ranking']].to_csv('../submissions/final_report.csv',index=False)\n",
    "first_try = pd.read_csv('../submissions/final_report.csv')\n",
    "first_try_zip = first_try.sort_values(\"ranking\", ascending=True)\n",
    "first_try_zip.to_csv('../submissions/submission_task_3_report.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
